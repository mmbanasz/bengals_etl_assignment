{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError #for debugging\n",
    "from dotenv import load_dotenv #for env variables\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the variables/password/IDs from the .env file\n",
    "load_dotenv()\n",
    "#get the access and secret key \n",
    "access_key_id = os.getenv('ACCESS_KEY_ID')\n",
    "secret_key = os.getenv('SECRET_ACCESS_KEY')\n",
    "\n",
    "#declare bucket name and data folder name where data will be downloaded to\n",
    "bucket_name = \"mindex-data-analytics-code-challenge\"\n",
    "data_folder = \"/Users/mady/mindex_data_analytics_challenge/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengals.csv downloaded successfully\n",
      "boyd_receiving.csv downloaded successfully\n",
      "chase_receiving.csv downloaded successfully\n",
      "higgins_receiving.csv downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "#create s3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=access_key_id, aws_secret_access_key=secret_key, region_name='us-east-1')\n",
    "\n",
    "#file names to download\n",
    "files = ['bengals.csv', 'boyd_receiving.csv', 'chase_receiving.csv', 'higgins_receiving.csv']\n",
    "\n",
    "#download each file\n",
    "for file in files:\n",
    "    try:\n",
    "        s3.download_file(bucket_name, file, data_folder + file)\n",
    "        print(file + \" downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(file + \"error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boyd dataframe created\n",
      "Chase dataframe created\n",
      "Higgins dataframe created\n",
      "****** Boyd df ****** \n",
      "     Week  Yards  TD Player\n",
      "0  REG1     32   0   Boyd\n",
      "1  REG2     73   0   Boyd\n",
      "2  REG3     36   1   Boyd\n",
      "3  REG4    118   0   Boyd\n",
      "4  REG5     24   0   Boyd\n",
      "****** Higgins df ****** \n",
      "     Week  Yards  TD   Player\n",
      "0  REG1     58   1  Higgins\n",
      "1  REG2     60   1  Higgins\n",
      "2  REG5     32   0  Higgins\n",
      "3  REG6     44   0  Higgins\n",
      "4  REG7     62   0  Higgins\n",
      "****** Chase df ****** \n",
      "     Week  Yards  TD Player\n",
      "0  REG1    101   1  Chase\n",
      "1  REG2     54   1  Chase\n",
      "2  REG3     65   2  Chase\n",
      "3  REG4     77   0  Chase\n",
      "4  REG5    159   1  Chase\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use the pandas library to load each CSV into its own dataframe.\n",
    "'''\n",
    "dataframes = {} #dictionary to hold the dataframes for each player\n",
    "player_files = ['/Users/mady/mindex_data_analytics_challenge/data/boyd_receiving.csv', '/Users/mady/mindex_data_analytics_challenge/data/chase_receiving.csv', '/Users/mady/mindex_data_analytics_challenge/data/higgins_receiving.csv']\n",
    "\n",
    "#put each file into a pandas dataframe\n",
    "for file in player_files:\n",
    "    csv = file.split('/data/')[1]\n",
    "    player_name = csv.split('_')[0].capitalize()\n",
    "    print(player_name + \" dataframe created\")\n",
    "    dataframes[player_name] = pd.read_csv(file)\n",
    "    #add player name as a column\n",
    "    dataframes[player_name]['Player'] = player_name\n",
    "\n",
    "#print out dataframe heads just created\n",
    "print('****** Boyd df ****** \\n ', dataframes['Boyd'].head())\n",
    "print('****** Higgins df ****** \\n ',dataframes['Higgins'].head())\n",
    "print('****** Chase df ****** \\n ',dataframes['Chase'].head())\n",
    "\n",
    "#load bengals data into a panda frame\n",
    "dataframes['Bangals'] = pd.read_csv('/Users/mady/mindex_data_analytics_challenge/data/bengals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Join/Merge all of the dataframes together to display one global table that shows\n",
    "the three different receiver’s yards and touchdown (TD) data as well as every\n",
    "game result. Be sure to include Opponent, Location, and Result fields from the\n",
    "bengals.csv file.\n",
    "\n",
    "Replace the ‘1.0’ or ‘0.0’ values in the Result field to display ‘Win’ or ‘Loss’,\n",
    "respectively.\n",
    "'''\n",
    "\n",
    "#concat the player data frames\n",
    "df = pd.concat([dataframes['Boyd'], dataframes['Higgins'], dataframes['Chase']])\n",
    "\n",
    "#join to the bengals data frame\n",
    "df = df.merge(dataframes['Bangals'], on='Week', how= 'right')\n",
    "df[['Yards', 'TD']] = df[['Yards', 'TD']].fillna(0)\n",
    "\n",
    "#replace the 1.0 and 0.0 values in the Result field\n",
    "df = df.replace({'Result': {1: 'Win', 0: 'Loss'}})\n",
    "df.index = range(1, len(df) + 1)\n",
    "\n",
    "#add indexs column so it's in CSV\n",
    "df['Index'] = range(1, len(df) + 1)\n",
    "\n",
    "#replace empty yard values with 0 (int)\n",
    "df['Yards'] = df['Yards'].replace('', 0).fillna(0).astype(int)\n",
    "df['TD'] = df['Yards'].replace('', 0).fillna(0).astype(int)\n",
    "\n",
    "#save the global dataframe to a csv file \n",
    "df.to_csv('/Users/mady/mindex_data_analytics_challenge/data/global.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get variaables from the .env file\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_username = os.getenv('USERNAME')\n",
    "db_password = os.getenv('PASSWORD')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_table_name = os.getenv('TABLE_NAME')\n",
    "db_address = os.getenv('ADDRESS')\n",
    "\n",
    "#db connection details \n",
    "#note address is the IP address from terminal running nslookup and the host given\n",
    "#because the host was not working to let me connect\n",
    "db = {\n",
    "    'dbname': db_name,\n",
    "    'user': db_username,\n",
    "    'password': db_password,\n",
    "    'host': db_address,\n",
    "    'port': '5432'\n",
    "}\n",
    "connection_string = 'postgresql+psycopg2://' + db_username + ':' + db_password + '@' + db_address + '/' + db_name\n",
    "#create SQLalchemy engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "#for debugging, prints my table\n",
    "def print_my_table():\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            query = f\"SELECT * FROM {db_table_name};\"\n",
    "            mb = pd.read_sql(query, con=connection.connection)\n",
    "            print(\"connection to DB successful, table to print below\")\n",
    "            print(mb)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error connecting to PostgreSQL DB: \", e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection to DB successful, table to print below\n",
      "Empty DataFrame\n",
      "Columns: [week, yards, td, player, opponent, location, result, index]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/b_wfgwbs4bz_t1zz98v8qgfr0000gn/T/ipykernel_19023/2712470670.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  mb = pd.read_sql(query, con=connection.connection)\n"
     ]
    }
   ],
   "source": [
    "#helper method to execute a query \n",
    "def execute_query_helper(query):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db)\n",
    "        cursor = conn.cursor()\n",
    "        alter_query = query\n",
    "        cursor.execute(alter_query)\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        #close connection\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "#delete contents from table \n",
    "execute_query_helper(\"\"\"DROP VIEW if exists results;\"\"\")\n",
    "execute_query_helper(\"\"\" DELETE FROM madison_banaszak; \"\"\")\n",
    "\n",
    "#remove columns\n",
    "execute_query_helper(\"\"\" ALTER TABLE madison_banaszak\n",
    "                     DROP COLUMN Week,\n",
    "        DROP COLUMN Yards,\n",
    "        DROP COLUMN TD,\n",
    "        DROP COLUMN Player,\n",
    "        DROP COLUMN Opponent,\n",
    "        DROP COLUMN Location,\n",
    "        DROP COLUMN Result,\n",
    "        DROP COLUMN Index;\n",
    "                     \"\"\")\n",
    "#add columms back in\n",
    "execute_query_helper(\"\"\"  \n",
    "        ALTER TABLE madison_banaszak\n",
    "        ADD COLUMN Week TEXT,\n",
    "        ADD COLUMN Yards INT,\n",
    "        ADD COLUMN TD INT,\n",
    "        ADD COLUMN Player TEXT,\n",
    "        ADD COLUMN Opponent TEXT,\n",
    "        ADD COLUMN Location TEXT,\n",
    "        ADD COLUMN Result TEXT,\n",
    "        ADD COLUMN Index INT;\n",
    "                     \"\"\")\n",
    "print_my_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to clean out table first before insert\n",
      "connection to DB successful, table to print below\n",
      "Empty DataFrame\n",
      "Columns: [week, yards, td, player, opponent, location, result, index]\n",
      "Index: []\n",
      "CSV file copied into table successfully :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/b_wfgwbs4bz_t1zz98v8qgfr0000gn/T/ipykernel_19023/2712470670.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  mb = pd.read_sql(query, con=connection.connection)\n",
      "/var/folders/m_/b_wfgwbs4bz_t1zz98v8qgfr0000gn/T/ipykernel_19023/2712470670.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  mb = pd.read_sql(query, con=connection.connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection to DB successful, table to print below\n",
      "     week  yards   td   player opponent location result  index\n",
      "0    PRE1      0    0                TB     Away    Win      1\n",
      "1    PRE2      0    0               WSH     Away   Loss      2\n",
      "2    PRE3      0    0               MIA     Home   Loss      3\n",
      "3    REG1     32   32     Boyd      MIN     Home    Win      4\n",
      "4    REG1     58   58  Higgins      MIN     Home    Win      5\n",
      "..    ...    ...  ...      ...      ...      ...    ...    ...\n",
      "58  POST3    103  103  Higgins       KC     Away    Win     59\n",
      "59  POST3     54   54    Chase       KC     Away    Win     60\n",
      "60  POST4     48   48     Boyd      LAR  Neutral   Loss     61\n",
      "61  POST4    100  100  Higgins      LAR  Neutral   Loss     62\n",
      "62  POST4     89   89    Chase      LAR  Neutral   Loss     63\n",
      "\n",
      "[63 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#get connection to db\n",
    "\n",
    "#delete contents from db before insert\n",
    "execute_query_helper(\"\"\" DELETE FROM madison_banaszak; \"\"\")\n",
    "conn = psycopg2.connect(**db)\n",
    "#create cursor object\n",
    "curr = conn.cursor()\n",
    "\n",
    "#open the csv file\n",
    "with open('/Users/mady/mindex_data_analytics_challenge/data/global.csv', 'r') as f:\n",
    "    #skip the header row\n",
    "    next(f)\n",
    "    #copy the csv file into the table\n",
    "    curr.copy_from(f, 'madison_banaszak', sep=',')\n",
    "    conn.commit()\n",
    "    curr.close()\n",
    "    conn.close()\n",
    "    print(\"CSV file copied into table successfully :)\")\n",
    "\n",
    "print_my_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Boyd Yards  Higgins Yards  Chase Yards Wins/Losses\n",
      "0         938           1400         1823     14 - 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/b_wfgwbs4bz_t1zz98v8qgfr0000gn/T/ipykernel_19023/3777064514.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  s = pd.read_sql(alter_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boyd Yards</th>\n",
       "      <th>Higgins Yards</th>\n",
       "      <th>Chase Yards</th>\n",
       "      <th>Wins/Losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>938</td>\n",
       "      <td>1400</td>\n",
       "      <td>1823</td>\n",
       "      <td>14 - 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Boyd Yards  Higgins Yards  Chase Yards Wins/Losses\n",
       "0         938           1400         1823     14 - 10"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Set up a connection to view the database using DBeaver and ensure all relevant\n",
    "data is present. Write a SQL Query to show the total yards each receiver had\n",
    "throughout the season as well as the team's record displayed as: “# of Wins - #\n",
    "of Losses”. Your query should generate the following view:\n",
    "'''\n",
    "def print_select_helper(query):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db)\n",
    "        cursor = conn.cursor()\n",
    "        alter_query = query\n",
    "        cursor.execute(alter_query)\n",
    "        s = pd.read_sql(alter_query, conn)\n",
    "        print(s)\n",
    "        return s\n",
    "                 \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        #close connection\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "execute_query_helper(\"\"\"DROP VIEW if exists results;\"\"\")\n",
    "execute_query_helper(\"\"\" CREATE OR REPLACE VIEW results as\n",
    "WITH yards AS (\n",
    "    SELECT\n",
    "        SUM(CASE WHEN Player = 'Boyd' THEN Yards ELSE 0 END) AS \"Boyd Yards\",\n",
    "        SUM(CASE WHEN Player = 'Higgins' THEN Yards ELSE 0 END) AS \"Higgins Yards\",\n",
    "        SUM(CASE WHEN Player = 'Chase' THEN Yards ELSE 0 END) AS \"Chase Yards\"\n",
    "    FROM madison_banaszak\n",
    "),\n",
    "wins_losses AS (\n",
    "  SELECT\n",
    " CONCAT(\n",
    "        SUM(CASE WHEN Result = 'Win' THEN 1 ELSE 0 END), \n",
    "        ' - ', \n",
    "        SUM(CASE WHEN Result = 'Loss' THEN 1 ELSE 0 END)\n",
    "    ) AS \"Wins/Losses\"\n",
    "FROM\n",
    "    (SELECT DISTINCT Week, Result FROM madison_banaszak) AS distinct_results\n",
    "    \n",
    ")\n",
    "SELECT * \n",
    "FROM  yards cross join wins_losses;\n",
    "\n",
    "                     \"\"\")\n",
    "\n",
    "print_select_helper(\"\"\" SELECT * FROM results; \"\"\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
